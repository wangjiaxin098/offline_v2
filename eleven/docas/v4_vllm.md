### twenty 10.4
Qwen3-0.6B模型
1.vllm服务器 分别基于cpu和gpu双模式运行
检查python环境
python3 --version

    2.loRA微调

    3.PySpark数据处理
    
    4.云端部署配置